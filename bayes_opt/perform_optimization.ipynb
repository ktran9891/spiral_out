{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktran/miniconda3/envs/art/lib/python2.7/site-packages/dragonfly/utils/oper_utils.py:30: UserWarning: cannot import name direct\n",
      "Could not import Fortran direct library. Dragonfly can still be used, but might be slightly slower. To get rid of this warning, install a numpy compatible Fortran compiler (e.g. gfortran) and the python-dev package and reinstall Dragonfly.\n",
      "  warn('%s\\n%s'%(e, fortran_err_msg))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import h5py\n",
    "from scipy import spatial\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from dragonfly import maximise_function\n",
    "from style_transfer import transfer_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n",
    "Load the information and models we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_folder = '../art_images/'\n",
    "\n",
    "# Load the classifier\n",
    "classifier = load_model('../sentiment_classification/resnet50_vso.h5')\n",
    "\n",
    "# Initialize the data generator we need to use to feed the classifier\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=True,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=True,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_attribute_match(encoded_feature_vector, attribute):\n",
    "    results_folder = update_style(encoded_feature_vector)\n",
    "\n",
    "    generator = datagen.flow_from_directory(results_folder,\n",
    "                                            target_size=(128, 128),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode=None,\n",
    "                                            shuffle=False)\n",
    "    probs = classifier.predict_generator(generator, len(os.listdir(img_folder)))\n",
    "\n",
    "    # Figure out how to calculate some objective function from the resnet output\n",
    "    return foo\n",
    "\n",
    "\n",
    "def update_style(encoded_feature_vector):\n",
    "    # Increment the counter for specifying which folder to save the images in\n",
    "    global updates\n",
    "    results_folder = './style_transfer_%03d' % updates\n",
    "    updates += 1\n",
    "\n",
    "    # Fetch various information that we'll be using\n",
    "    global current_image\n",
    "\n",
    "    # Find the closest image to the vector provided, then transfer its style\n",
    "    global tree\n",
    "    global image_names\n",
    "    _, image_index = tree.query(encoded_feature_vector)\n",
    "    style_image = image_names[image_index]\n",
    "    current_image = transfer_style(current_image, style_image,\n",
    "                                   result_folder=results_folder)\n",
    "\n",
    "    # Remove the style image from the list of candidates (to avoid redos)\n",
    "    del image_names[image_index]\n",
    "    global encoded_features\n",
    "    encoded_features = np.delete(encoded_features, image_index, axis=0)\n",
    "\n",
    "    # Update some global variables\n",
    "    global style_images\n",
    "    style_images.append(style_image)\n",
    "    tree = spatial.KDTree(encoded_features)\n",
    "\n",
    "    return results_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiral out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametercs\n",
    "seed_image = 'me.jpg'\n",
    "attribute = 'foo'\n",
    "max_capital = 2\n",
    "\n",
    "\n",
    "# Load image names and initialize the list of style images\n",
    "with open(art_folder + 'image_mapping.txt', 'r') as file_handle:\n",
    "    image_names = file_handle.readlines()\n",
    "image_names = [name.split('\\n')[0] for name in image_names]\n",
    "style_images = []\n",
    "\n",
    "\n",
    "# Read the encoded features, then make a KDTree from them for matching\n",
    "h5f = h5py.File(art_folder + 'features.h5', 'r')\n",
    "encoded_features = h5f['encoded_features'][:]\n",
    "h5f.close()\n",
    "tree = spatial.KDTree(encoded_features)\n",
    "\n",
    "# Figure out the domain for dragonfly to use\n",
    "maxes = encoded_features.max(axis=0)\n",
    "mins = encoded_features.min(axis=0)\n",
    "domain = [(min_, max_) for min_, max_ in zip(mins, maxes)]\n",
    "\n",
    "\n",
    "# Let's go!\n",
    "current_image = copy.deepcopy(seed_image)\n",
    "updates = 0\n",
    "max_val, max_pt, history = maximise_function(lambda features: calc_attribute_match(features, attribute),\n",
    "                                             domain, max_capital)\n",
    "\n",
    "# Save it before we lose it!\n",
    "seed_name = seed_image.split('.')[0]\n",
    "with open('history_for_%s_%s.pkl' % (attribute, seed_name), 'rb') as file_handle:\n",
    "    pickle.dump(history, file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
