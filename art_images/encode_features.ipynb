{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features\n",
    "h5f = h5py.File('features.h5', 'r')\n",
    "features = h5f['ResNet_features'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data up\n",
    "train_size = 0.8\n",
    "features_train, features_validate = train_test_split(features,\n",
    "                                                     train_size=train_size,\n",
    "                                                     test_size=1-train_size,\n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(x_train, x_validate,\n",
    "                  n_latent_vars, latent_activation, decoder_activation,\n",
    "                  optimizer, loss, epochs, batch_size):\n",
    "    # Make the tensors so that we can define the *coders\n",
    "    n_dimen = x_train.shape[1]\n",
    "    input_shape = (n_dimen,)\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    latent_tensor = Dense(n_latent_vars, activation=latent_activation)(input_tensor)\n",
    "    output_tensor = Dense(n_dimen, activation=decoder_activation)(latent_tensor)\n",
    "\n",
    "    # Make and train the autoencoder\n",
    "    encoder = Model(input_tensor, latent_tensor)\n",
    "    autoencoder = Model(input_tensor, output_tensor)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=loss)\n",
    "    stopper = EarlyStopping(patience=3)\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_validate, x_validate),\n",
    "                    callbacks=[stopper])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/40\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.5453 - val_loss: 0.4841\n",
      "Epoch 2/40\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.4512 - val_loss: 0.4274\n",
      "Epoch 3/40\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.3972 - val_loss: 0.3876\n",
      "Epoch 4/40\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.3608 - val_loss: 0.3611\n",
      "Epoch 5/40\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.3347 - val_loss: 0.3439\n",
      "Epoch 6/40\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.3151 - val_loss: 0.3318\n",
      "Epoch 7/40\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.2997 - val_loss: 0.3200\n",
      "Epoch 8/40\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.2882 - val_loss: 0.3126\n",
      "Epoch 9/40\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.2795 - val_loss: 0.3070\n",
      "Epoch 10/40\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.2736 - val_loss: 0.3033\n",
      "Epoch 11/40\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.2681 - val_loss: 0.3012\n",
      "Epoch 12/40\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.2645 - val_loss: 0.2985\n",
      "Epoch 13/40\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.2617 - val_loss: 0.2970\n",
      "Epoch 14/40\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.2597 - val_loss: 0.2956\n",
      "Epoch 15/40\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.2576 - val_loss: 0.2948\n",
      "Epoch 16/40\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.2561 - val_loss: 0.2940\n",
      "Epoch 17/40\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.2550 - val_loss: 0.2939\n",
      "Epoch 18/40\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.2540 - val_loss: 0.2928\n",
      "Epoch 19/40\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.2530 - val_loss: 0.2935\n",
      "Epoch 20/40\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.2524 - val_loss: 0.2929\n",
      "Epoch 21/40\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.2519 - val_loss: 0.2918\n",
      "Epoch 22/40\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.2512 - val_loss: 0.2922\n",
      "Epoch 23/40\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.2511 - val_loss: 0.2924\n",
      "Epoch 24/40\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.2505 - val_loss: 0.2927\n"
     ]
    }
   ],
   "source": [
    "# Train shallow [auto]encoder\n",
    "n_latent_vars = 16\n",
    "autoencoder, encoder = train_encoder(x_train=features_train,\n",
    "                                     x_validate=features_validate,\n",
    "                                     n_latent_vars=n_latent_vars,\n",
    "                                     latent_activation='softplus',\n",
    "                                     decoder_activation='softplus',\n",
    "                                     optimizer='adam',\n",
    "                                     loss='mean_squared_error',\n",
    "                                     epochs=40,\n",
    "                                     batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the autoencoder and encoder\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.save('autoencoder.h5')\n",
    "encoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "encoder.save('encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_39 to have shape (2048,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-992dab30e707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_latent_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mencoded_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mencoded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_features_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_39 to have shape (2048,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# Now let's actually use the encoder on all the images\n",
    "encoded_features = np.empty((0, n_latent_vars))\n",
    "for feature in features:\n",
    "    encoded_features_ = encoder.predict(feature)\n",
    "    encoded_features = np.append(encoded_features, encoded_features_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then save the encoded features\n",
    "h5f = h5py.File('features.h5', 'w')\n",
    "h5f.create_dataset('ResNet_features', data=features)\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_conda",
   "language": "python",
   "name": "my_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
