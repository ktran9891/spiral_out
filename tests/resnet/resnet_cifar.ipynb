{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ktran/miniconda3/envs/art/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:From /home/ktran/miniconda3/envs/art/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktran/miniconda3/envs/art/lib/python2.7/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, validation_data=(array([[[..., steps_per_epoch=1562, epochs=50, callbacks=[<keras.ca..., max_queue_size=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1562/1562 [==============================] - 36s 23ms/step - loss: 1.7972 - acc: 0.4874 - val_loss: 1.4438 - val_acc: 0.5928\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 1.3851 - acc: 0.6084 - val_loss: 1.5200 - val_acc: 0.5903\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 1.2325 - acc: 0.6577 - val_loss: 1.1047 - val_acc: 0.6985\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 1.1375 - acc: 0.6867 - val_loss: 1.1122 - val_acc: 0.6890\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 1.0732 - acc: 0.7083 - val_loss: 1.1592 - val_acc: 0.6827\n",
      "Epoch 6/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 1.0270 - acc: 0.7248 - val_loss: 1.0623 - val_acc: 0.7086\n",
      "Epoch 7/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.9957 - acc: 0.7355 - val_loss: 1.1708 - val_acc: 0.6880\n",
      "Epoch 8/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.9622 - acc: 0.7498 - val_loss: 0.9020 - val_acc: 0.7672\n",
      "Epoch 9/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.9383 - acc: 0.7581 - val_loss: 0.9117 - val_acc: 0.7672\n",
      "Epoch 10/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.9252 - acc: 0.7626 - val_loss: 0.9037 - val_acc: 0.7713\n",
      "Epoch 11/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.9036 - acc: 0.7715 - val_loss: 0.9917 - val_acc: 0.7399\n",
      "Epoch 12/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.8879 - acc: 0.7773 - val_loss: 0.9084 - val_acc: 0.7692\n",
      "Epoch 13/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.8684 - acc: 0.7849 - val_loss: 1.0309 - val_acc: 0.7465\n",
      "Epoch 14/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.7333 - acc: 0.8259 - val_loss: 0.7464 - val_acc: 0.8185\n",
      "Epoch 15/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.6896 - acc: 0.8362 - val_loss: 0.7359 - val_acc: 0.8206\n",
      "Epoch 16/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.6601 - acc: 0.8442 - val_loss: 0.7111 - val_acc: 0.8269\n",
      "Epoch 17/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.6390 - acc: 0.8473 - val_loss: 0.7381 - val_acc: 0.8180\n",
      "Epoch 18/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.6215 - acc: 0.8529 - val_loss: 0.7159 - val_acc: 0.8206\n",
      "Epoch 19/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.6080 - acc: 0.8570 - val_loss: 0.7359 - val_acc: 0.8146\n",
      "Epoch 20/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5926 - acc: 0.8622 - val_loss: 0.7010 - val_acc: 0.8320\n",
      "Epoch 21/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5829 - acc: 0.8632 - val_loss: 0.7234 - val_acc: 0.8176\n",
      "Epoch 22/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5746 - acc: 0.8656 - val_loss: 0.7419 - val_acc: 0.8139\n",
      "Epoch 23/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5703 - acc: 0.8673 - val_loss: 0.6886 - val_acc: 0.8306\n",
      "Epoch 24/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.5615 - acc: 0.8679 - val_loss: 0.6990 - val_acc: 0.8285\n",
      "Epoch 25/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5512 - acc: 0.8735 - val_loss: 0.6951 - val_acc: 0.8297\n",
      "Epoch 26/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5484 - acc: 0.8735 - val_loss: 0.7042 - val_acc: 0.8264\n",
      "Epoch 27/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5351 - acc: 0.8790 - val_loss: 0.6842 - val_acc: 0.8357\n",
      "Epoch 28/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5376 - acc: 0.8770 - val_loss: 0.7167 - val_acc: 0.8276\n",
      "Epoch 29/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5289 - acc: 0.8800 - val_loss: 0.7157 - val_acc: 0.8278\n",
      "Epoch 30/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5243 - acc: 0.8818 - val_loss: 0.7171 - val_acc: 0.8276\n",
      "Epoch 31/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5177 - acc: 0.8831 - val_loss: 0.7070 - val_acc: 0.8300\n",
      "Epoch 32/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.5166 - acc: 0.8837 - val_loss: 0.7533 - val_acc: 0.8166\n",
      "Epoch 33/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.4556 - acc: 0.9047 - val_loss: 0.6541 - val_acc: 0.8480\n",
      "Epoch 34/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.4324 - acc: 0.9121 - val_loss: 0.6642 - val_acc: 0.8428\n",
      "Epoch 35/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.4180 - acc: 0.9159 - val_loss: 0.6601 - val_acc: 0.8459\n",
      "Epoch 36/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.4069 - acc: 0.9180 - val_loss: 0.6751 - val_acc: 0.8419\n",
      "Epoch 37/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.4020 - acc: 0.9205 - val_loss: 0.6652 - val_acc: 0.8460\n",
      "Epoch 38/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.3957 - acc: 0.9213 - val_loss: 0.6832 - val_acc: 0.8421\n",
      "Epoch 39/50\n",
      "1562/1562 [==============================] - 34s 22ms/step - loss: 0.3777 - acc: 0.9281 - val_loss: 0.6597 - val_acc: 0.8461\n",
      "Epoch 40/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.3638 - acc: 0.9327 - val_loss: 0.6614 - val_acc: 0.8490\n",
      "Epoch 41/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.3591 - acc: 0.9349 - val_loss: 0.6614 - val_acc: 0.8488\n",
      "Epoch 42/50\n",
      "1562/1562 [==============================] - 32s 20ms/step - loss: 0.3539 - acc: 0.9352 - val_loss: 0.6652 - val_acc: 0.8480\n",
      "Epoch 43/50\n",
      "1562/1562 [==============================] - 32s 21ms/step - loss: 0.3528 - acc: 0.9358 - val_loss: 0.6636 - val_acc: 0.8501\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import resnet\n",
    "\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('resnet18_cifar10.csv')\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "#nb_epoch = 200\n",
    "nb_epoch = 50\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3 \n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128.\n",
    "\n",
    "model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
